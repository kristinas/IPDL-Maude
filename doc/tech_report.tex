\documentclass[11pt,hidelinks]{article}
\usepackage{amsmath, amssymb, amsthm, stmaryrd}
\usepackage{url}
\usepackage{tikz}
\usetikzlibrary{positioning}
\usepackage[override]{cmtt}
\usepackage{textcomp}
\usepackage{cryptocode}
\usepackage[T1]{fontenc}
\usepackage{fancyvrb}
\usepackage{mathtools}
\usepackage{savesym}
\usepackage{physics}
\savesymbol{div}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{graphics}
\usepackage{caption, subcaption}
\usepackage{xspace}
\usepackage{pl-syntax}
\usepackage{tensor}
\usepackage{adjustbox}
\usepackage{graphicx}
\usepackage{mathpartir}
\usepackage[margin=0.5in]{geometry}
\usepackage{mathtools}
\usepackage{float}
\usepackage[colorlinks]{hyperref}
\usepackage{mathabx}
\hypersetup{linkcolor=blue,filecolor=blue,citecolor=blue,urlcolor=blue}

\newcommand{\nat}{\mathbb{N}}
\newcommand{\ipdl}{\textsf{IPDL} }
\newcommand{\type}{\mathsf{t}}
\newcommand{\func}{\mathsf{f}}
\newcommand{\dist}{\mathsf{d}}
\newcommand{\one}{\mathsf{1}}
\newcommand{\Bool}{\mathsf{Bool}}
\newcommand{\true}{\mathsf{true}}
\newcommand{\false}{\mathsf{false}}
\newcommand{\fst}{\mathsf{fst}}
\newcommand{\snd}{\mathsf{snd}}
\newcommand{\ret}[1]{\mathsf{ret} \ #1}
\newcommand{\samp}[1]{\mathsf{samp} \ #1}
\renewcommand{\read}[1]{\mathsf{read} \ #1}
\newcommand{\ifte}[3]{\mathsf{if} \ #1 \ \mathsf{then} \ #2 \ \mathsf{else} \ #3}
\newcommand{\zero}{\mathsf{0}}
\newcommand{\assign}[2]{#1 \coloneqq #2}
\newcommand{\Par}[2]{#1 \; || \; #2}
\newcommand{\new}[3]{\mathsf{new} \ #1 : #2 \ \mathsf{in} \ #3}
\newcommand{\axiom}{\mathsf{axiom}}
\renewcommand{\approxeq}[6]{#1 \approx #2 : #3 \to #4 \ \mathsf{width} \ #5 \ \mathsf{length} \ #6}
\newcommand{\sem}[1]{\llbracket #1 \rrbracket}
\newcommand{\val}[1]{\mathsf{val} \ #1}
\newcommand{\outstep}[2]{\xmapsto{#1 \, \coloneqq \, #2}}
\newcommand{\stuck}{\mathsf{stuck}}
\newcommand{\final}{\mathsf{final}}
\renewcommand{\norm}[1]{\Vert #1 \Vert}
\renewcommand{\eval}[1]{#1 \! \Downarrow}
\newcommand{\lift}[1]{\mathcal{L}(#1)}
%\newcommand{\in}[2]{\langle #1 \coloneqq #2 \rangle}
\newcommand{\pull}[2]{\stackrel{\hookleftarrow}{#1 \, \coloneqq \, #2}}
\newcommand{\newNf}{\mathsf{newNF}}
\newcommand{\preNf}{\mathsf{preNF}}
\newcommand{\nf}{\mathsf{NF}}

\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}						
\newtheorem{definition}{Definition}	
\newtheorem{corollary}{Corollary}	
\newtheorem{example}{Example}

\begin{document}
\title{A Core Calculus for Equational Proofs of Distributed Cryptographic Protocols: Technical Report}

\maketitle

\section*{\small Acknowledgement}
This project was funded through the NGI Assure Fund, a fund established by NLnet with financial support from the European Commission's Next Generation Internet programme, under the aegis of DG Communications Networks, Content and Technology under grant agreement No. 957073.

\section{Syntax of \ipdl}
\input{syntax}

\section{Operational Semantics of \ipdl}
\input{semantics}

\section{Soundness of Exact Equality in \ipdl}
\input{soundness}

%\section{Computational Semantics of \ipdl}
%The second step is to define an \emph{interaction}, seen as a \emph{security game}, between an \ipdl program and a resource-bounded, probabilistic \emph{distinguisher}. The interaction semantics is used to validate \emph{approximate} observational equivalences: these are used for cryptographic hardness assumptions, such as the security of encryption schemes or Diffie-Hellman, as well as top-level statements of security for protocols.

%\section{Case Studies in \ipdl}
%In this section, we briefly describe the case studies we have completed in \ipdl so far. The full proofs are available in a separate document \cite{case_studies}. We demonstrate through lines of code that the proof effort of \ipdl scales well with increasing
%protocol complexity, see Figure~\ref{fig:cases}.
%
%\begin{figure}
%\begin{center}
%\begin{tabular}{|l|l|}
%\hline
%Case study & Lines of Code \\
%\hline
%A2S: CPA & 239 LoC \\
%\hline
%OT: Pre-Processing & 480 LoC \\
%\hline
%Multi-Party Coin Flip & 2019 LoC \\
%\hline
%\end{tabular}
%\end{center}
%\caption{Case Studies in \textsf{ipdl}.}
%\label{fig:cases}
%\end{figure}
%
%
%
%In this section, we briefly describe the case studies we have completed in \ipdl, and outline several key proof steps that conveniently employ equational reasoning. Our case studies range from simple communication protocols to a two-party GMW protocol and a multi-party coin flip protocol. We demonstrate through lines of code that the proof effort of \ipdl scales well with increasing protocol complexity, see Figure~\ref{fig:cases}.

%\subsection{Communication Protocols}
%%We prove secure two different communication protocols that construct a secure communication channel from an authenticated one. The authenticated channels allow the adversary to observe in-flight messages and schedule delivery of them; in contrast, the secure communication channels only allow the adversary to observe the \emph{presence} of the channel, but none of the message contents.
%
%\subsubsection{Secure Communication from CPA Security}
%In our first case study (Section 1 of \cite{case_studies}), we prove secure a communication protocol that constructs a secure communication channel from an authenticated one. The authenticated channels allow the adversary to observe in-flight messages and schedule delivery of them; in contrast, the secure communication channels allow the adversary to schedule messages but grant no access to the message contents. We note that in this setup, the ability of the adversary to delay the messages sent over the secure channel is inherited from the corresponding control of the adversary over the authenticated channel.
%
%%is a generalization of our example from Section~\ref{sec:overview} to allow the adversary to schedule the delivery of each message. In line with Section~\ref{sec:overview}, we prove that a CPA-secure encryption scheme may be used alongside an authenticated channel to achieve a secure one. 
%
%\subsection{Oblivious Transfer Protocols}
%We next consider a particular Oblivious Transfer (OT) construction. This example (Section 2 of \cite{case_studies}) is proven secure in the \emph{semi-honest} (or \emph{honest-but-curious}) setting, where all parties operate correctly, but corrupt parties leak all private data to the adversary. We prove that the leaked values reveal no private information about the honest parties. To encode semi-honest corruption, we augment the protocols with appropriate \emph{leakage} functions that forward to the adversary all values visible to the corrupted parties. In turn, the simulator must take as input the leakages in the ideal protocol
%(usually minimal), and output suitable leakages in the real protocol.
%
%
%
%
%%We next consider several Oblivious Transfer (OT) constructions secure. These examples are proven in the \emph{semi-honest} (or \emph{honest-but-curious}) setting, where we assume the parties operate correctly, but corrupt parties leak all private data to the adversary. We prove that leaked values reveal no private information about the honest parties. To encode semi-honest corruption, we augment the protocols with \emph{leakage} functions that send all values visible to the corrupted party to the adversary. 
%
%In (1-out-of-2) OT, Bob wishes to obtain exactly one of Alice's two messages, without revealing his choice~\cite{gmw}. Alice doesn't learn which message Bob asked for, while Bob doesn't learn the other of the two messages. The ideal functionality simply receives the two messages $m_0,m_1$ from the sender, the choice bit $c$ from the receiver, and outputs $m_i$. We analyze the most interesting case when Bob is semi-honest and Alice is honest. Hence, the real-world leakages are derived solely from the input $i$ coming from the receiver, and the output $m_i$ coming from the ideal functionality, with no access to any information about message $m_{1-i}$.
%
%%We prove the security of three main OT constructions from the literature:
%%first, we show that 1-out-of-4 OT, which is used by our GMW example, can
%%be realized from three instances of an ideal 1-out-of-2 OT~\cite{naor1999oblivious};
%%then, we show a \emph{preprocessing} result for OT, which allows Alice
    %%and Bob to establish an OT in an offline phase, then use this OT for a
        %%fast online phase~\cite{beaver1995precomputing}; finally, we show that 1-out-of-2 OT can be realized using a trapdoor permutation and a hard-core bit predicate~\cite{gmw}.
%%
%%To illustrate how \ipdl allows us to carry out probabilistic reasoning, we outline here a few key steps from the second construction. 
%%In the pre-processing phase, Alice randomly generates a new pair of keys $(k_0,
%%k_1)$, while Bob randomly decides on one of these keys, obtaining a
%%choice bit $j$. They then
%%use the underlying (idealized) OT to securely transfer the randomly chosen key
%%$k_j$ to Bob.
%%
%%In the online phase, Bob encrypts his actual choice bit $i$ by $\mathsf{xor}$-ing it
%%with $j$, chosen randomly in the prior phase. He sends his encrypted choice $i
%%\oplus j$ to Alice, who responds by first swapping her two keys if $i \oplus j$ is
%%true, then sending Bob her two keys, $\mathsf{xor}$-ed with their respective
%%messages. Bob has enough information to recover his chosen message, but the
%%other one appears uniformly random. 
%%
%%To prove that Bob does not learn any information about the message he did not ask for, we carry out two probabilistic arguments. The first, which we call \emph{decoupling}, observes that selecting two keys $k_0,k_1$ from the same distribution $\mu$, and then randomly deciding to return either $(k_0,k_1)$ or $(k_1,k_0)$ is perfectly indistinguishable from just returning $(k_0,k_1)$. To see this, consider the protocol
%%where $\Key(0)$ and $\Key(1)$ are assigned the reaction $\samp{\mu}$, and 
%%\begin{align*}
    %%\KeyPair &\coloneqq f \leftarrow \samp{\flip}; \ k_0 \leftarrow \Key(0); \
    %%k_1 \leftarrow \Key(1); \ \ifte{f}{\ret{(k_1,k_0)}}{\ret{(k_0,k_1)}}.
%%\end{align*}
%%Here the channels $\Key(0),\Key(1)$ are internal and the channel $\KeyPair$ is an output. We fold the two key samplings into the channel $\KeyPair$:
%%\begin{align*}
    %%\KeyPair &\coloneqq f \leftarrow \samp{\flip}; \ \mathsf{if} \ f \ \mathsf{then} \ {\color{red} k_0 \leftarrow \samp{\mu}; \ k_1 \leftarrow \samp{\mu};} \ \ret{(k_1,k_0)} \\ 
    %%& {\color{white} \KeyPair \coloneqq f \leftarrow \Flip; \ \mathsf{if} \ f \ }{\mathsf{else} \ {\color{red} k_0 \leftarrow \samp{\mu}; \ k_1 \leftarrow \samp{\mu};} \ \ret{(k_0,k_1)}}
%%\end{align*}
%%
%%Since the samplings are interchangeable, we end up doing the same thing either way:
%%\begin{align*}
    %%\KeyPair & \coloneqq f \leftarrow \samp{\flip}; \ \mathsf{if} \ f \ \mathsf{then} \ {\color{red} k_1 \leftarrow \samp{\mu}; \ k_0 \leftarrow \samp{\mu};} \ \ret{(k_1,k_0)} \\ 
    %%&{\color{white} \KeyPair \coloneqq f \leftarrow \Flip; \ \mathsf{if} \ f \ }{\mathsf{else} \ k_0 \leftarrow \samp{\mu}; \ k_1 \leftarrow \samp{\mu};} \ \ret{(k_0,k_1)}
%%\end{align*}
%%
%%So we may just as well not flip:
%%\[ \KeyPair \coloneqq k_0 \leftarrow \samp{\mu}; \ k_1 \leftarrow \samp{\mu}; \
%%\ret{(k_0,k_1)}. \]
%%We emphasize that no complex probabilistic reasoning is necessary in the
%%argument, but only a few simple application of equational proof rules. 
%%
%%The second probabilistic argument concerns the distribution $\mu$, which
%%represents uniform randomness. 
%%Rather than modeling uniform randomness intrinsically in Coq, we only need to
%%introduce the (sound) axiom that $\mu = (x \leftarrow \mu;\ \unit{x \oplus y})$ for any
%%bitstring $y$. 
%
%\subsection{Multi-Party Coin Flip Protocol}
%Our first large case study (Section 3 of \cite{case_studies}) is for a protocol that allows an arbitrary number of mutually distrusting parties to collaboratively generate fair randomness, due to Blum~\cite{blum1983coin}. To do so, each party locally generates randomness, and commits it to all other parties. We assume an idealized commitment functionality that also bakes in a notion of broadcast, to prevent equivocation. Each party decommits their randomness once all other commitments have been collected; the output of the protocol is the Boolean sum of all decommitments.
%
%Unlike previous examples, this example is secure in the \emph{malicious} model. We model malicious parties by assigning them a \emph{shell}, which simply forwards all information between the protocol and the adversary.
%
%\section{Maude Formalization}
%\input{maude}

\bibliography{bib} 
\bibliographystyle{ieeetr}

\end{document}